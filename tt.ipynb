{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/loicsteve/Desktop/AI Agents/First-Agent-Using-smolagents/smolagents/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, FinalAnswerTool, HfApiModel, load_tool, tool\n",
    "import datetime\n",
    "import requests\n",
    "import pytz\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def my_custom_tool(arg1:str, arg2:int)-> str: # it's important to specify the return type\n",
    "    # Keep this format for the tool description / args description but feel free to modify the tool\n",
    "    \"\"\"A tool that does nothing yet \n",
    "    Args:\n",
    "        arg1: the first argument\n",
    "        arg2: the second argument\n",
    "    \"\"\"\n",
    "    return \"What magic will you build ?\"\n",
    "\n",
    "@tool\n",
    "def get_current_time_in_timezone(timezone: str) -> str:\n",
    "    \"\"\"A tool that fetches the current local time in a specified timezone.\n",
    "    Args:\n",
    "        timezone: A string representing a valid timezone (e.g., 'America/New_York').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create timezone object\n",
    "        tz = pytz.timezone(timezone)\n",
    "        # Get current time in that timezone\n",
    "        local_time = datetime.datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        return f\"The current local time in {timezone} is: {local_time}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching time for timezone '{timezone}': {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "It uses Qwen/Qwen2.5-Coder-32B-Instruct as the LLM engine. This is a very capable model that weâ€™ll access via the serverless API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GradioUI' from 'Gradio_UI' (/Users/loicsteve/Desktop/AI Agents/First-Agent-Using-smolagents/Gradio_UI.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGradio_UI\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradioUI\n\u001b[1;32m      5\u001b[0m final_answer \u001b[38;5;241m=\u001b[39m FinalAnswerTool()\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m HfApiModel(\n\u001b[1;32m      7\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2096\u001b[39m,\n\u001b[1;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQwen/Qwen2.5-Coder-32B-Instruct\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     custom_role_conversions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GradioUI' from 'Gradio_UI' (/Users/loicsteve/Desktop/AI Agents/First-Agent-Using-smolagents/Gradio_UI.py)"
     ]
    }
   ],
   "source": [
    "final_answer = FinalAnswerTool()\n",
    "model = HfApiModel(\n",
    "    max_tokens=2096,\n",
    "    temperature=0.5,\n",
    "    model_id='Qwen/Qwen2.5-Coder-32B-Instruct',\n",
    "    custom_role_conversions=None,\n",
    ")\n",
    "\n",
    "with open(\"prompts.yaml\", 'r') as stream:\n",
    "    prompt_templates = yaml.safe_load(stream)\n",
    "    \n",
    "# We're creating our CodeAgent\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    tools=[final_answer], # add your tools here (don't remove final_answer)\n",
    "    max_steps=6,\n",
    "    verbosity_level=1,\n",
    "    grammar=None,\n",
    "    planning_interval=None,\n",
    "    name=None,\n",
    "    description=None,\n",
    "    prompt_templates=prompt_templates\n",
    ")\n",
    "\n",
    "GradioUI(agent).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(\n",
    "max_tokens=2096,\n",
    "temperature=0.5,\n",
    "model_id='Qwen/Qwen2.5-Coder-32B-Instruct',# it is possible that this model may be overloaded\n",
    "custom_role_conversions=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\"Qwen/Qwen2.5-Coder-32B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " paris\n"
     ]
    }
   ],
   "source": [
    "output = client.text_generation(\n",
    "    \"The capital of france is\",\n",
    "    max_new_tokens=1,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smolagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
